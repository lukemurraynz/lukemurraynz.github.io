"use strict";(self.webpackChunklukemurraynz=self.webpackChunklukemurraynz||[]).push([[30146],{89724:(e,o,t)=>{t.r(o),t.d(o,{assets:()=>l,contentTitle:()=>s,default:()=>d,frontMatter:()=>a,metadata:()=>i,toc:()=>u});var r=t(74848),n=t(28453);const a={title:"Deploying Large Language Models on AKS with Kaito",metaDescription:"Learn how to deploy large language models (or Small Language Models) on Azure Kubernetes Service (AKS) using Kaito, an operator that automates the deployment of AI/ML inference models in a Kubernetes cluster.",description:"Deploy large language models on AKS using Kaito, an operator that simplifies the deployment of AI/ML inference models in a Kubernetes cluster.",date:new Date("2024-05-08T21:49:34.752Z"),tags:["Azure"],categories:["Azure"],authors:["Luke"],header:"kaito-arch.png",slug:"azure/run-local-llm-aks",keywords:["azure","large language models","AKS","Kaito","Kubernetes","operator","AI/ML inference models","GPU-enabled nodes","deployment","model provisioning","model configuration","model tuning","model deployment","model management","open-source LLMs","cost reduction","data security","AI Shared responsibility model","AKS cluster","quota","GPU compute nodes","Azure CLI","GitHub Codespace","infrastructure as code","Terraform","Azure Developer CLI","deployment","AKS cluster deployment","region","environment configuration","deployment completion","microservices","Pets app","AKS demos","experiments","polyglot architecture","event-driven design","open-source back-end services","RabbitMQ","MongoDB","OpenAI's GPT-3 models","generative text","graphics creation","MongoDB instance","RabbitMQ","prerequisites","Azure subscription","GPU compute workload","Standard NCSv3","Azure Developer CLI","Terraform","AKS cluster deployment"]},s=void 0,i={permalink:"/azure/run-local-llm-aks",source:"@site/blog/2024-05-09-run-local-slm-aks/index.mdx",title:"Deploying Large Language Models on AKS with Kaito",description:"Deploy large language models on AKS using Kaito, an operator that simplifies the deployment of AI/ML inference models in a Kubernetes cluster.",date:"2024-05-08T21:49:34.752Z",tags:[{label:"Azure",permalink:"/tags/azure"}],readingTime:15.855,hasTruncateMarker:!0,authors:[{name:"Luke Murray",title:"Author",url:"https://luke.geek.nz",imageURL:"https://luke.geek.nz/img/logo.png",key:"Luke"}],frontMatter:{title:"Deploying Large Language Models on AKS with Kaito",metaDescription:"Learn how to deploy large language models (or Small Language Models) on Azure Kubernetes Service (AKS) using Kaito, an operator that automates the deployment of AI/ML inference models in a Kubernetes cluster.",description:"Deploy large language models on AKS using Kaito, an operator that simplifies the deployment of AI/ML inference models in a Kubernetes cluster.",date:"2024-05-08T21:49:34.752Z",tags:["Azure"],categories:["Azure"],authors:["Luke"],header:"kaito-arch.png",slug:"azure/run-local-llm-aks",keywords:["azure","large language models","AKS","Kaito","Kubernetes","operator","AI/ML inference models","GPU-enabled nodes","deployment","model provisioning","model configuration","model tuning","model deployment","model management","open-source LLMs","cost reduction","data security","AI Shared responsibility model","AKS cluster","quota","GPU compute nodes","Azure CLI","GitHub Codespace","infrastructure as code","Terraform","Azure Developer CLI","deployment","AKS cluster deployment","region","environment configuration","deployment completion","microservices","Pets app","AKS demos","experiments","polyglot architecture","event-driven design","open-source back-end services","RabbitMQ","MongoDB","OpenAI's GPT-3 models","generative text","graphics creation","MongoDB instance","RabbitMQ","prerequisites","Azure subscription","GPU compute workload","Standard NCSv3","Azure Developer CLI","Terraform","AKS cluster deployment"]},unlisted:!1,prevItem:{title:"Export Azure DevOps Repositories to Azure Storage Account",permalink:"/azure/export-azure-devops-repos-azure-storage-account"},nextItem:{title:"Authorization Permission Mismatch error with Azure Storage",permalink:"/azure/authorization-permission-mismatch-error-azure-storage"}},l={authorsImageUrls:[void 0]},u=[];function c(e){const o={a:"a",blockquote:"blockquote",em:"em",p:"p",...(0,n.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsxs)(o.p,{children:["Today, we are going to look at deploying a large language model ",(0,r.jsx)(o.em,{children:"(LLM)"})," directly into your AKS ",(0,r.jsx)(o.em,{children:"(Azure Kubernetes Service)"})," cluster, running on GPU-enabled nodes, using ",(0,r.jsxs)(o.a,{href:"https://github.com/Azure/kaito",children:["Kaito ",(0,r.jsx)(o.em,{children:"(Kubernetes AI Toolchain Operator)"})]}),"."]}),"\n",(0,r.jsxs)(o.blockquote,{children:["\n",(0,r.jsx)(o.p,{children:"KAITO is an open-source operator that transforms how you deploy AI models on Kubernetes. It streamlines the process, automating critical tasks like infrastructure provisioning and resource optimization. It intelligently selects the optimal hardware configuration for your specific model, using available CPU and GPU resources on AKS. KAITO eliminates the manual setup complexities, accelerating your deployment time and reducing associated costs."}),"\n"]})]})}function d(e={}){const{wrapper:o}={...(0,n.R)(),...e.components};return o?(0,r.jsx)(o,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},28453:(e,o,t)=>{t.d(o,{R:()=>s,x:()=>i});var r=t(96540);const n={},a=r.createContext(n);function s(e){const o=r.useContext(a);return r.useMemo((function(){return"function"==typeof e?e(o):{...o,...e}}),[o,e])}function i(e){let o;return o=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:s(e.components),r.createElement(a.Provider,{value:o},e.children)}}}]);